{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "\n",
    "In this challenge, you'll try to predict the severity of car accidents, based on features collected from after-crash police investigation\n",
    "\n",
    "This [Kaggle challenge](https://www.kaggle.com/c/accident-severity) comprises of 1,000,000 accidents report, split into multiple `.csv` files.\n",
    "\n",
    "Download the data [here](https://wagon-public-datasets.s3.amazonaws.com/04-ML_08-workflow_datasets.zip). For instance:\n",
    "\n",
    "```\n",
    "cd ~/code/$GITHUB_NICKNAME/data-challenges/05-ML/08-Workflow/01-Car-accidents-severity\n",
    "curl https://wagon-public-datasets.s3.amazonaws.com/car_acccidents_datasets.zip > data.zip\n",
    "unzip data.zip -d data\n",
    "rm -rf data.zip\n",
    "```\n",
    "**The goal of the model is to predict the severity of car accidents**. The target variable is called `grav` (for 'gravity') in the file `users.csv`. This variable has four levels, but in this challenge, we'll convert it to a binary classification problem.\n",
    "\n",
    "We will:\n",
    "- Load data into pandas\n",
    "- Create a single DataFrame for our model\n",
    "- Extract the features you think would be relevant and build a data pipeline\n",
    "- Then, iterate on the different phase and try to get the best model! \n",
    "\n",
    "We will give you the basic preprocessing, and you will build and improve the models and feature engineering.\n",
    "\n",
    "‚ö†Ô∏è **Some very important good practices to follow for large exploratory notebooks**\n",
    "- Build your Notebook linearily so that it can always be run from top to bottom without any errors\n",
    "- Regularity clean the outputs of your cells that are not needed\n",
    "- Clean the variables that are not needed using python built-in function `del`, or the the Jupyter nbextentions `variable_inspector`\n",
    "- Make heavy use of `table_of_content` and `collapsable_headings` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data sourcing\n",
    "\n",
    "Let's get started! The data we want to use is from the `csv` files in `/data/data_training`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brunolajoie/.pyenv/versions/3.7.7/envs/lewagon414/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (15) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "cara = pd.read_csv(\"data/data_training/caracteristics.csv\", encoding=\"ISO-8859-1\")\n",
    "users = pd.read_csv(\"data/data_training/users.csv\", encoding=\"ISO-8859-1\")\n",
    "places = pd.read_csv(\"data/data_training/places.csv\", encoding=\"ISO-8859-1\")\n",
    "vehicles = pd.read_csv(\"data/data_training/vehicles.csv\", encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Explore the different tables, and the different variables using `challenge_variable.md`, which provides a description of features. More details can be found [here](https://static.data.gouv.fr/resources/base-de-donnees-accidents-corporels-de-la-circulation/20180927-112352/description-des-bases-de-donnees-onisr-annees-2005-a-2017.pdf) if needed, or in the [Kaggle](https://www.kaggle.com/ahmedlahlou/accidents-in-france-from-2005-to-2016/discussion) discussion channel. Understand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì We will create one single dataset where each row should represent a `user` in a car, by merging the data from the different files dataset.  \n",
    "**Take some time to think about how you would do it yourself**, and only then, read carefully through the code below to understand exactly what we did"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Merge caracteristics and places on 'Num_Acc'\n",
    "data = cara.merge(places, on='Num_Acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a common key to merge users amd vehicles on\n",
    "users['Num_Acc_num_veh'] = users['Num_Acc'].map(lambda x: str(x)) + users['num_veh']\n",
    "vehicles['Num_Acc_num_veh'] = vehicles['Num_Acc'].map(lambda x: str(x)) + vehicles['num_veh']\n",
    "# Remove useless columns\n",
    "vehicles = vehicles.drop(columns=['index'])\n",
    "users = users.drop(columns=['index', 'Num_Acc', 'num_veh'])\n",
    "# Merge vehicles and users\n",
    "tmp = vehicles.merge(users, on='Num_Acc_num_veh', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all datasets on 'Num_Acc'\n",
    "data = data.merge(tmp, on='Num_Acc', how='inner')\n",
    "del tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1209362, 54)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "We will apply some preprocessing methods like standardization or missing values removal or imputing.\n",
    "Remember to look at `challenge_variable.md` for a description of features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop lines without targets (if any)\n",
    "data_cleaned = data[~np.isnan(data.grav)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Check whih features with highest ratio of NaN per column\n",
    "(data_cleaned.isna().sum() / data_cleaned.shape[0]).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove too incomplete features\n",
    "too_incomplete_features=[\n",
    "    'locp', 'actp', 'etatp'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove features that can be safely considered useless for the predictive power of our model\n",
    "useless_features=[\n",
    "    'v2', 'lat', 'long', 'gps', 'pr1', 'pr', 'v1', 'adr', 'voie',\n",
    "    'index_x', 'Num_Acc', 'Num_Acc_num_veh', 'Num_Acc', 'num_veh', 'index_y',\n",
    "    'jour', 'an',\n",
    "    'dep', 'com', 'env1',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaned.drop(columns=too_incomplete_features+useless_features, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The secu feature seams extremely important. Let's handle this one specifically.\n",
    "# Drop lines without 'secu'\n",
    "data_cleaned = data_cleaned[~np.isnan(data.secu)]\n",
    "# Only keep rows with \"secu\" number consisting of two digits\n",
    "data_cleaned = data_cleaned[data_cleaned.secu.map(lambda x: len(str(round(x)))) == 2]\n",
    "# Split as per feature description\n",
    "data_cleaned['safety_equipment'] = data_cleaned.secu.map(lambda x: str(round(x))[0])\n",
    "data_cleaned['is_safety_equipment'] = data_cleaned.secu.map(lambda x: str(round(x))[1])\n",
    "data_cleaned.drop(columns=['secu'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1125397, 33)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace hrmn by hh only (minue granularity is considered useless)\n",
    "data_cleaned['hour_of_day'] = pd.Series(data_cleaned.hrmn.map(lambda x: str(x)[0:-2])).replace('', 0)\n",
    "data_cleaned.drop(columns=['hrmn'], inplace=True)\n",
    "data_cleaned.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a `data_cleaned` dataset! Let's now engineer our features as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare features and target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cyclical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_cyclical = ['hour_of_day', 'mois']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE BELOW\n",
    "def preprocess_cyclical_features(X):\n",
    "    '''\n",
    "    Input: DataFrame X\n",
    "    Output: Returns new DataFrame, where all its features X_i have been replaced\n",
    "    by both their sin(X_i) and cos(X_i), and delete initial feature X_i.\n",
    "    '''\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Check your code below\n",
    "preprocess_cyclical_features(data_cleaned[features_cyclical])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Do you get a Warning \"A value is trying to be set on a copy of a slice from a DataFrame\"?\n",
    "If so, it may be because you are trying to modify the input DataFrame `data_cleaned`!\n",
    "\n",
    "Read this [important blog on copy vs. view](https://www.practicaldatascience.org/html/views_and_copies_in_pandas.html) of pandas DataFrame and try to solve your warning by yourself\n",
    "\n",
    "\n",
    "\n",
    "<details>\n",
    "    <summary>Hint</summary>\n",
    "\n",
    "`pd.DataFrame.copy()`\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_numerical = ['nbv', 'senc', 'an_nais', 'occutc', 'lartpc', 'larrout']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "\n",
    "def preprocess_numerical_features(X):\n",
    "    '''\n",
    "    Returns a new DataFrame with\n",
    "    - Missing values replaced by Column Mean\n",
    "    - Features Standard Scaled\n",
    "    - Original Features names kept in the DataFrame\n",
    "    '''\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### categorical features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Create the last group of feature (categorical features) without hardcoding them manually. Then, create the associated preprocessing method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_categorical = list(set(data_cleaned.columns) - set(features_numerical) - set(features_cyclical) - {'grav'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_categorical_features(X):   \n",
    "    ''' Returns a new DataFrame with dummified columns'''\n",
    "    df = X.copy()\n",
    "    return pd.get_dummies(df.apply(lambda col: col.astype('category')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Create the new `data_preprocessed` dataset by concatenating all three preprocessing, and then drop all remaining NaN that could not have been handled previously despite our preprocessing. You should have a (1125397, 216) shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1125397, 216)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE BELOW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Dataset\n",
    "‚ùì Create X and y, and don't forget to convert the classification into a binary task\n",
    "For instance:\n",
    "\n",
    "```python\n",
    "data['grav_binary'] = data['grav'].replace({1: 0, 4: 0, 2: 1, 3: 1})\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a smaller dataset (X_small, y_small) for investigation purpose only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test Split both datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (optional) Create here - only when needed - an train/eval split within the train set itself.\n",
    "# Some powerfull models (XGBOOST, Neural Network...) which are prone to overfitting on the traning set, needs \"early stopping criteria\", to avoid descending the gradient completely and avoid overfitti."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You now have a dataset ready for training! \n",
    "**Skip directly to section 5 to get a baseline model working ASAP**, and only then come back to this section 4 if you want to better understand your X and get inspiration for the best model to use, or for some feature selection to reduce model complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùìInvestigate your X. Are features strongly correlated? Are some feature more important than other?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùìFit a PCA and plot the cumulated sum of explained variance ratio of your Principal Component. Do you see any clear elbow?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forest-based most important features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Fit a default RandomForestClassifier on a small smaple to estimate the top 20 feature importance. Do they make intuitive sense to your point of view?  Do you see any clear elbow for dimension-reduction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì (Optional) There are better ways to estimate feature importance in a RandomForest. Feel free to try to two following options\n",
    "\n",
    "**Option 1** : Recursive-method\n",
    "1. Train a first model, note top1 feature (computed based on the gini-explicative power of the feature, in each tree)\n",
    "2. Remove top1 from your X and retrain a RandomForest. Note top1 feature and it's relative importance\n",
    "3. Loop\n",
    "\n",
    "**Option 2** : Permutation-method ([sklearn.inspection.permutation_importance](https://scikit-learn.org/stable/modules/permutation_importance.html#permutation-importance)), works with any model!\n",
    "1. Train a first model, keep track of its accuracy\n",
    "2. Take one feature and shuffle its columns. Compute new accuracy of the corrupted dataset, and note by how much it has been reduced.\n",
    "3. Loop over all features and rank them by accuracy reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline performance metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì What is the class balance of your target?  \n",
    "\n",
    "What would be the most dumb baseline to beat? Print the `classification_report` of this dumb model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì If you don't want to favor any class over the other, what would be a good performance metric for your problem? \n",
    "Take some time to think before reading the answer! It's not that obvious."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Answer</summary>\n",
    "\n",
    "In such an unbalanced problem, accuracy is meaningless: A very dumb model predicting always zeros would have great accuracy, to the detriment of the predictive power of class  1, which has precision and recall equal to zero!\n",
    "    \n",
    "The non-weighted mean between both f1 score of each class called `f1_macro` would be a good measure for this type of problem.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Model (A first iteration)\n",
    "\n",
    "‚ùì Create a simple model, fast to train, to classify the severity of the accidents. Start simple. Don't forget to fit on your training set and evaluate the score on your test set. Can you beat the Baseline? What about its Accuracy? Measure the time it takes on the full dataset, with `%%time` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# YOUR CODE BELOW\n",
    "%%time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üî•üî•üî• Advanced Models - LeWagon batch contest ! üî•üî•üî•"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Now it's your turn to shine! Play with different models and try to find the best one on your training set!\n",
    "- Send your best score (as defined above) to your slack channel without saying which model you used!\n",
    "- ‚ö†Ô∏è Only send score tested on the `y_test` of complete size (1M+ rows!)\n",
    "- Feel free to use your X_small for investigation purpose\n",
    "- If it takes too long to train, simplify your model, or use better feature preprocessing/selection\n",
    "\n",
    "The winner will present its notebook to the class during the reboot üí™\n",
    "\n",
    "(Don't forget, your Notebook should be made to be run from top to bottom in one go!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) - Pipeline most steps (prepross & fit) in one single Sklearn Pipeline"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "230.797px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "368px",
    "left": "927px",
    "right": "20px",
    "top": "141px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
