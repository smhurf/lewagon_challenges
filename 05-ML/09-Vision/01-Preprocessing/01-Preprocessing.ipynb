{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 - Preprocessing\n",
    "\n",
    "In computers, images can be stored in multi-dimensional arrays. We will use some classic datasets used in computer vision.\n",
    "\n",
    "Let's start with CIFAR10. This dataset blablabla\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution\n",
    "\n",
    "### Simple Matrices\n",
    "\n",
    "It is possible to do operations on images using convolutions. The main idea is to use a matrix which is called a *kernel* and apply it the matrix containing the image for instance. This is the method used in software like Gimp of Photoshop.\n",
    "\n",
    "Convolution is very important to transform images and for instance perform data augmentation. It can also be useful to decrease the importance of image elements that are not useful for the classification (for instance, we don't need the image background to detect cats, and we don't want the classifier to learn things related to this). It is also an important first step to understand Convolutional Neural Networks (CNN) that are the deep learning best tools to work on images.\n",
    "\n",
    "You can find more information about convolution [here](http://setosa.io/ev/image-kernels/) and [here](http://machinelearninguru.com/computer_vision/basics/convolution/image_convolution_1.html).\n",
    "\n",
    "To get insights about this concept, we will play a bit with matrices and kernels.\n",
    "\n",
    "You will create a matrix (corresponding to an image) and a kernel which is also a matrix as following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3],\n",
       "       [ 4,  5,  6,  7],\n",
       "       [ 8,  9, 10, 11],\n",
       "       [12, 13, 14, 15]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = np.arange(16).reshape(4, 4)\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 0]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel = np.array([\n",
    "    [0, 0, 0],\n",
    "    [0, 1, 0],\n",
    "    [0, 0, 0],\n",
    "])\n",
    "kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will try to \"apply\" the kernel to the image matrix. Use the function `convolve2d` and set the parameter `mode='same'`. It will use zero-padding to be sure that the output has the same shape than the input.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that it returns the `img` matrix unchanged.\n",
    "\n",
    "Now, try the following kernel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0],\n",
       "       [0, 2, 0],\n",
       "       [0, 0, 0]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel = np.array([\n",
    "    [0, 0, 0],\n",
    "    [0, 2, 0],\n",
    "    [0, 0, 0],\n",
    "])\n",
    "kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the center value of the kernel is the only non-zero value. This means that values around will not be taken into account in the convolution. Let's try the following kernel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1],\n",
       "       [1, 1, 1],\n",
       "       [1, 1, 1]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel = np.array([\n",
    "    [1, 1, 1],\n",
    "    [1, 1, 1],\n",
    "    [1, 1, 1],\n",
    "])\n",
    "kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be sure to understand what is going on here. For instance the first value is 10: it is the sum 4, 5 and 1. The other cells are zero because of zero-padding.\n",
    "\n",
    "If these matrices were images, then each value is the luminance value for a pixel. When we do convolution, the center of the kernel corresponds to the a pixel and depending to the other values in the kernel the pixels around it will be taken into account to calculate the new luminance value. It is thus possible to do blurs and different filter effects.\n",
    "\n",
    "Let's see on a real image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the library `imageio` to load the image `test_img1.jpg`. Install Pillow with `pip install Pillow`. It is needed to use `imageio`. Then, display the image using Matplotlib."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, you should divide by 255 to have the image on the range [0, 1]. The matrix convolutions will output floats and to plot images, Matplotlib needs either to have image on the range [0, 1] for floats or in the range [0, 255] for integers.\n",
    "\n",
    "Then, use the following kernel to transform the image:\n",
    "\n",
    "```python\n",
    "np.array([\n",
    "    [0, 0, 0],\n",
    "    [0, 1, 0],\n",
    "    [0, 0, 0],\n",
    "])\n",
    "```\n",
    "\n",
    "When it is done, display the resulting image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we seen before, this kernel doesn't change our image. But, it shows that our convolution code is working.\n",
    "\n",
    "Now, try to apply different kernels in order to create the following filters:\n",
    "\n",
    "- edge detection\n",
    "- gaussian blur\n",
    "- sharpen\n",
    "\n",
    "You should find the corresponding kernels on this [Wikipedia page](https://en.wikipedia.org/wiki/Kernel_(image_processing)).\n",
    "\n",
    "Also, try a blur with kernels of different size to see the effect of the kernel size.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that these filters can be applied before using the images in the algorithms depending on the task we want to do. You can note that with CNN, this preprocessing step is something that are done by the network: the kernel values are something that can be learned by the neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "Another way to preprocess images are tools that we have seen applied on other type of data, like standardization and normalization.\n",
    "\n",
    "These steps are important as data preparation for deep learning for instance, zero-centering was used in:\n",
    "\n",
    "- AlexNet: ImageNet Classification with Deep Convolutional Neural Networks\n",
    "\n",
    "- VGG: Very Deep Convolutional Networks for Large-Scale Image Recognition\n",
    "\n",
    "- ResNet: Deep Residual Learning for Image Recognition\n",
    "\n",
    "\n",
    "One important thing to keep is mind is that these tools need to be applied across the data samples.\n",
    "\n",
    "For instance, if we are working with a dataset of 100 images of size 32px x 32px, the corresponding matrix will have a shape of (100, 32, 32). If we flatten the height and the weight, we end up with a matrix of shape (100, 1024).\n",
    "\n",
    "So here, what is the number of data samples and what is the number of features?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are clear with that, go to the following part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To experiment on standardization, normalization, we will use a classic dataset: CIFAR10. Try to find an easy way to get it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should end up with the variables:\n",
    "\n",
    "- `X_train` (shape: (50000, 32, 32, 3))\n",
    "- `y_train` (shape: (50000, 1))\n",
    "- `X_test` (shape: (10000, 32, 32, 3))\n",
    "- `y_test` (shape: (10000, 1))\n",
    "\n",
    "This means that there are 50,000 image in `X_train` for instance. Each image is a 32px by 32px image with 3 color dimensions.\n",
    "\n",
    "Try to plot the following image: `X_train[2000]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see a horse (note the low definitions of these images).\n",
    "\n",
    "You will be able to try different preprocessing methods now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by reshaping `X_train` to have the shape samples by pixel (50000, 3072)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zero-Centering\n",
    "\n",
    "With *zero-centering* or *mean subtraction*, the mean is subtracted from the training data. There are multiple ways to do it. It is common to do a per-pixel mean subtraction: for each pixel you calculate the mean across the training set and do the subtraction.\n",
    "\n",
    "Try to apply zero-centering to `X_train` (create a new variable called `X_train_zero`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, to plot the result, it is necessary to rescale the values between 0 and 1. This is because they are floats. If values are integers, matplotlib needs values between 0 and 255.\n",
    "\n",
    "Try to rescale `X_train_zero` between 0 and 1. Then, plot few images and look if they are different from the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see that there is a slight visual difference with the bright colors but this difference is small."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardization\n",
    "\n",
    "You can now do the standardization with the same approach than with zero-centering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check that your answer is correct, look at the mean and standard deviation for one pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can also be easier to use `StandardScaler` from Sklearn. Try to get the same result with `StandardScaler`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do again some plots to see the difference between raw images and standardized images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
