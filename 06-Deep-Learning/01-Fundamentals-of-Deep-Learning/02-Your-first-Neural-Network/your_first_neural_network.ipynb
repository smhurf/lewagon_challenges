{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning week - Day 1 - Your First Neural Network\n",
    "\n",
    "### Exercise objectives\n",
    "- Write your first Neural Network\n",
    "- Inspect some of the most important hyperparameters of Neural Networks\n",
    "\n",
    "<hr>\n",
    "<hr>\n",
    "\n",
    "\n",
    "In this exercise, you will build your first Neural Network that will separate two classes.\n",
    "Each data $X$ has only two coordinate $X = (x_1, x_2)$ and belongs to the class 0 or to the class 1. It is called the two moons dataset. \n",
    "\n",
    "As there is only two features, it can be represented on a graph, where the color corresponds to one of the two classes. Here is an example of such data : \n",
    "\n",
    "![Two moons](moons_example.png)\n",
    "\n",
    "\n",
    "\n",
    "## 1. Create data\n",
    "\n",
    "Here, we will use the scikit-learn `make_moons` function [(see documentation here)](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_moons.html) that creates 2 moons that cannot be linearly separated. Each moon correspond to a class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "\n",
    "### Data generation\n",
    "X, y = make_moons(n_samples=300, noise=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This function allows to plot the two moons\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_moons(X, y):\n",
    "    df = pd.DataFrame(dict(x=X[:,0], y=X[:,1], label=y))\n",
    "    colors = {0:'red', 1:'blue'}\n",
    "    fig, ax = plt.subplots()\n",
    "    grouped = df.groupby('label')\n",
    "\n",
    "    for key, group in grouped:\n",
    "        group.plot(ax=ax, kind='scatter', x='x', y='y', label=key, color=colors[key])\n",
    "    plt.show()\n",
    "\n",
    "plot_moons(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì  Play with the number of samples and the noise to see the effect on the data, by plotting the moons for different values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Draw 250 samples of the data with a noise equal to 0.20 (random state being 0) and split the initial dataset into a train and test set (size: 70/30%)\n",
    "\n",
    "Remark : Please call the variables `X_train`, `y_train`, `X_test` and `y_test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Simple model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will now define your first neural network.\n",
    "The architecture of your model should be : \n",
    "- a first layer with 5 neurons, with activation function being `relu` and the correct input dimension\n",
    "- a output layer suited to your 2-class classification problem.\n",
    "\n",
    "\n",
    "‚ùì Complete the next function (in the `#TODO`) with the previous architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model():\n",
    "    \n",
    "    ### Model architecture\n",
    "    ### To do \n",
    "    ### To do\n",
    "    ### To do\n",
    "    \n",
    "    ### Model optimization : Optimizer, loss and metric    \n",
    "    model.compile(loss='binary_crossentropy', \n",
    "                  optimizer='adam', \n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = initialize_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùó **Remark** ‚ùó Briefly speaking, the compile tells your algorithm how to optimize the weights of your network once it will be fit onto real data. \"binary_crossentropy\" is the \"log-loss\" that you have already seen in Machine-Learning.\n",
    "\n",
    "‚ùì How many parameters does the model have?  \n",
    "Double check using the `summary` function that display the stack of layers, the shape of the output after each layer, and the number of parameters of each layer. Use this function to check that you have 21 parameters i.e. weights in your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are now ready to train your algorithm on some data :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = initialize_model()\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "                    epochs=100,\n",
    "                    batch_size=8,\n",
    "                    verbose=0) # Try different verbose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`history` contains information about the training.\n",
    "\n",
    "‚ùì Inspect all its attributes using `history.__dict__`. You will see epoch-by-epoch info stored in `history.history`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Plot the history of the train loss using the following function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.title('Train loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict & Evaluate performance on test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can either predict `y_pred` using the `.predict()` method..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or you can also `evaluate()` method to directly return the loss value & performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The first element corresponds to the **loss** value, set to `\"binary_crossentropy\"` in `model.compile()`. Its value hard to interpret.\n",
    "\n",
    "- The second element is the **metrics**, that we set to `\"accuracy\"`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì What is your accuracy on the test test?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Check your prediction visually using our `plot_decision_regions` available in `utils/plots.py`. It does look a bit underfitted, isn't it? We will create a deeper network next!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.plots import plot_decision_regions\n",
    "plot_decision_regions(X,y, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üß™ Test your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "result = ChallengeResult('first_model', accuracy=accuracy)\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Variations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Relaunch the model on 500 iterations\n",
    "- Don't forget to call the `initialize_model` function, otherwise, your initial parameters will be those you already learned on the previous fit!!)\n",
    "- Plot the history to see how the loss changed over the different epochs/iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Did the test accuracy improve?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not necessarily...So when to stop?\n",
    "The answer will be seen tomorrow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Let's try **deeper** architecture that includes : \n",
    "\n",
    "- a first layer with 20 neurons (activation being relu)\n",
    "- a second layer with 10 neurons (activation being relu)\n",
    "- a third layer with 5 neurons (activation being relu)\n",
    "- an output layer suited for this problem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì What is the number of parameters of your new model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run your model on the previous data with 500 epochs and plot the loss afterwards.  \n",
    "‚ùì What is your accuracy on the test test? Store it as `accuracy_deep`variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_deep = ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Do you think we have overfitted on the noise? Check it out below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decision_regions(X_train,y_train, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üß™ **Test your code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "result = ChallengeResult('deeper_model',\n",
    "                         accuracy=accuracy_deep)\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üèÅ **Congratulation! Push and commmit this notebook before moving to the next**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
