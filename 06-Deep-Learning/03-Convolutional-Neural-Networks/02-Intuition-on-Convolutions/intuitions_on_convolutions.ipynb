{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning week - Day 3 - Intuition on Convolutions\n",
    "\n",
    "### Exercise objectives\n",
    "- Compute convolution operations\n",
    "- Visualize a convolution kernel\n",
    "- VIsualize the effect of a convolution on images\n",
    "\n",
    "<hr>\n",
    "<hr>\n",
    "\n",
    "\n",
    "**Convolutional Neural Networks** correspond the Neural Networks that are specially designed to work on images. \n",
    "\n",
    "This is made possible thanks to _convolutions_. This specific mathematical operations applies a _kernel_ to an input image and creates an output representation. The name of this output can change depending on the community. Here, let's talk about the output as it corresponds to the output of a layer, as in standard DL neurons. But it can also be \"convoluted representation/feature\", \"convolution\", or also \"activation\" as it corresponds to the activation of a given layer.\n",
    "\n",
    "<img src=\"convolution.png\" width=\"300\">\n",
    "\n",
    "⚠️ It is important to get that the same kernel, i.e. the same weights, are applied to different zones of the images. This is very different from standard DL operations where each weight of each neuron is related to only one input coordinate (which in this case would be each pixel). Here, the weight of a kernel is not applied to only one input, i.e. one pixel, but to different pixels, \"step by step\".\n",
    "\n",
    "You can think of each kernel (or each filter in case of color image) as a magnifying glass through which you see the image. Similarly to your eyes which have to do not capture everything at once, but that have to look at different parts before to capture the whole thing you are looking at.\n",
    "\n",
    "So let's see a bit deeper at convolutions in general, and their impact in Convolutional Neural Networks.\n",
    "\n",
    "\n",
    "# Data\n",
    "\n",
    "❓ First use the following function to load the data. \n",
    "\n",
    "⚠️ Restrict any desire to change the shapes or types of the outputs, this can arm further questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib.pyplot import imread\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def load_data(path):\n",
    "    nb_circles = 100\n",
    "    nb_triangles = 100\n",
    "    \n",
    "    X, y = [], []\n",
    "    \n",
    "    for i in range(nb_circles):\n",
    "        c_path = os.path.join(path, 'circles', f'circle_{i}.png')\n",
    "        X.append(imread(c_path)[:, :, :1])\n",
    "        y.append(0)\n",
    "    \n",
    "    for i in range(nb_triangles):\n",
    "        t_path = os.path.join(path, 'triangles', f'triangle_{i}.png')\n",
    "        X.append(imread(t_path)[:, :, :1])\n",
    "        y.append(1)\n",
    "        \n",
    "    c = list(zip(X, y))\n",
    "    np.random.shuffle(c)\n",
    "    X, y = zip(*c)\n",
    "        \n",
    "    return np.array(X), np.array(y)\n",
    "        \n",
    "X, y = load_data('data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect the data. \n",
    "\n",
    "❓ Check the shape of your data. Especially, why an additional dimension of size 1 for `X`? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ Do the input images need some normalization? If so, do it with Keras utils or by yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ Display some images and their respective label (the images are black and white, therefore use `cmap=gray` in the dedicated matplotlib function - otherwise, you will get unrelevant and weird colors)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ How many classes to predict are there? It should already give you an information on the last layer of your CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutions\n",
    "\n",
    "The following function allows to apply a kernel to an image => a convolution. \n",
    "\n",
    "⚠️ Be careful though as _convolution_ operation are slighlty different in signal processing. For instance, the numpy.convolve function does not compute the convolution in the Deep Learning sense.\n",
    "\n",
    "⚠️ Keras convolutions are a bit more complex as they deal with padding and slide. This is a simplified example.\n",
    "\n",
    "⚠️ Be careful: convolution sometimes refers to _one_ operation. Sometimes to the operations repeated on the entire image.\n",
    "\n",
    "❓ Load the function and go through the lines to understand what it is doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_convolution(img, kernel):\n",
    "    # Parameters\n",
    "    kernel = np.array(kernel)\n",
    "    kernel_height, kernel_width = kernel.shape\n",
    "\n",
    "    img = np.squeeze(img) # Removes dimensions of size 1\n",
    "    img_height, img_width = img.shape\n",
    "    \n",
    "    array = []\n",
    "\n",
    "    for x in range(img_height-kernel_height):\n",
    "        arr = []\n",
    "        \n",
    "        for y in range(img_width - kernel_width):\n",
    "            \n",
    "            a = np.multiply(img[x:x+kernel_height, y:y+kernel_width], kernel)\n",
    "            arr.append(a.sum())\n",
    "            \n",
    "        array.append(arr)\n",
    "        \n",
    "    return array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "❓ Apply the convolution with the following kernel to any image from the input dataset. Display the input and output image to see the difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "identity_kernel = [\n",
    "    [0, 0, 0],\n",
    "    [0, 1, 0],\n",
    "    [0, 0, 0]\n",
    "]\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous kernel corresponds to the _identity_ kernel, meaning that the output is equal to the output... It basically does nothing. You can easily figure this out by thinking about the operation it does on the image : only one pixel per convolution operation is kept as the other are multiplied by 0.\n",
    "\n",
    "❓ Repeat the operation with the following function with the following kernel, once on an triangle and once on a rectangle. \n",
    "\n",
    "The following printing function ease the visualization. (let activation to `False`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_1 = [\n",
    "    [1, 1, 1],\n",
    "    [0, 0, 0],\n",
    "    [-1, -1, -1]\n",
    "]\n",
    "\n",
    "def plot_convolution(img, kernel, activation=False):\n",
    "    img = np.squeeze(img)\n",
    "    output_img = compute_convolution(img, kernel)\n",
    "    if activation:\n",
    "        output_img = np.maximum(output_img, 0)\n",
    "    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    \n",
    "    ax1 = plt.subplot2grid((3,3),(0,0), rowspan=3)\n",
    "    ax1.imshow(img, cmap='gray')\n",
    "    ax1.title.set_text('Input image')\n",
    "    \n",
    "    ax2 = plt.subplot2grid((3,3),(1, 1))\n",
    "    ax2.imshow(kernel, cmap='gray')\n",
    "    ax2.title.set_text('Kernel')    \n",
    "    \n",
    "    ax3 = plt.subplot2grid((3,3),(0, 2), rowspan=3)\n",
    "    ax3.imshow(output_img, cmap='gray')\n",
    "    ax3.title.set_text('Output image')    \n",
    "\n",
    "    for ax in [ax1, ax2, ax3]:\n",
    "        ax.axes.get_xaxis().set_visible(False)\n",
    "        ax.axes.get_yaxis().set_visible(False)\n",
    "    \n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ Let's try to understand why this is meaningful. First, white colors correspond to high values and black to low values. In a neural network, just after a regular neuron or a convolution, there is an activation function. When the activation function is a `relu`, it just correponds to setting the negative values to 0.\n",
    "\n",
    "Well, let's see what it means in the case of a CNN. Rerun the previous functions with `activation` set to `True` (in this case, the activation fuction _is_ the relu)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ This kernel is actually highlithing the edges in a given direction. Try the next following kernels to check the different edges it can detect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_2 = [\n",
    "    [-1, -1, -1],\n",
    "    [0, 0, 0],   \n",
    "    [1, 1, 1],\n",
    "]\n",
    "\n",
    "kernel_3 = [\n",
    "    [-1, 0, 1],\n",
    "    [-1, 0, 1],\n",
    "    [-1, 0, 1]\n",
    "]\n",
    "\n",
    "kernel_4 = [\n",
    "    [1, 0, -1],\n",
    "    [1, 0, -1],\n",
    "    [1, 0, -1]\n",
    "]\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ This is not always easy to understand what the kernel is going to do. Nonetheless, try different kernels to see their effect on the image. Moreover, the size of kernel before was arbitrary. You should also try to change it.\n",
    "\n",
    "Tip: you can use the `numpy.random.uniform` function to try kernels at random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you got the idea of what the convolution is doing, let's see how it goes in a real Convolutional Neural Network.\n",
    "\n",
    "# Convolutional Neural Network\n",
    "\n",
    "\n",
    "❓ Write a convolutional network that has \n",
    "- a convolutional layer with 32 filters with (5, 5) kernels.\n",
    "- a convolutional layer with 54 filters with (3, 3) kernels.\n",
    "\n",
    "After the flattening and before the last layer, you can add a Dense layer of the size of your choice - be reasonable.\n",
    "And do not forget to add a max-pooling layer (with (2, 2) pool sizes) after each convolution.\n",
    "\n",
    "Also, be sure to compile your model with the adequate parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model():\n",
    "    # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ Fit the model. You should achieve a accuracy of at least 90. Here, the point is not to bother with overfitting, so do not worry much as you would have to if you have a high score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There is only has many kernels per filters are there are channels in the input: So 1 channel in the first convolutional layer and 36 channels per filters in the second convolutional layer\n",
    "- There is 32 filters in the first convolution and 64 filters in the second convolution.\n",
    "\n",
    "Due to the way the weights are stored in Keras, look at the following function that allows you to get a specific kernel given the layer number (the convolutions corresponds to the 0th and 2nd layer), and the filter_number. Here, the channel number is fixed.\n",
    "\n",
    "❓ Get some kernels and display them to see what the CNN has learnt. Especially, apply this kernel to an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kernel(layer_number, filter_number, channel_number):\n",
    "\n",
    "    weight_or_bias = 0\n",
    "    k = model.layers[layer_number].weights[0].numpy()[:, :, channel_number, filter_number]\n",
    "\n",
    "    return k\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ Display some kernels from the second convolutional layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can visualize the activation of the CNN after the second convolution. However, you would need to compute the activations after the first layer, then compute the MaxPooling, etc.\n",
    "\n",
    "For these reason, we will use a function which computes the different activation through the entire network. This will ease the representation. \n",
    "\n",
    "⚠️ The following lines and function are using specific Keras functions and attributes. There are out of the scope of today's exercises, therefore do not spend much time trying to understand them. On the other hand, these functions might be very useful during the project weeks as there happens to be projects related to imaging data. In such situation, you can come back to the following code to better understand it ;)\n",
    "\n",
    "❓ Run the following cell. The function allows to directly print the activation after the second layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_outputs = [layer.output for layer in model.layers]\n",
    "activation_model = models.Model(inputs=model.input, outputs=layer_outputs)\n",
    "activations = activation_model.predict(X) \n",
    "\n",
    "\n",
    "def get_activation(activations, image_number, layer_number, filter_number):\n",
    "    return activations[layer_number][image_number][:, :, filter_number]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ Display the output after the second convolution layer - choose any image and filter number. You can play around to see how the information of an image _flows_ within the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ Now, you have all the tools to go a step further. Here, re-initialize a new CNN but with 4 convolution layers. The different parameters are up to you to choose. Once fit on your data, observe the activation throughout the network to see how the input images are transformed after the convolutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you should get a better understanding of what the convolutions are doing and how the related information thus flows within the neural network in order to obtain accurate prediction. \n",
    "\n",
    "# Miscellaneous\n",
    "\n",
    "The following simply presents the functions that created the dataset you are working with.\n",
    "\n",
    "They were left at the end of the notebook in case you want to further prototype and get better understanding of what is going on. But do not prototype yet => you can go to the next exercise as for now, and come back to it any time later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_triangle():\n",
    "    dx = np.random.uniform(0.1, 0.3)\n",
    "    dy = np.random.uniform(0.1, 0.3)\n",
    "    noise_x = np.random.uniform(0.0, 0.1)\n",
    "    noise_y = np.random.uniform(0.0, 0.1)    \n",
    "    \n",
    "    x = np.random.uniform(0, 1-dx-noise_x)\n",
    "    y = np.random.uniform(0, 1-dy)\n",
    "    X = np.array([[x,y], [x+dx+noise_x,y], [x+dx/2, y+dy+noise_y]])\n",
    "\n",
    "    t1 = plt.Polygon(X, color='black')\n",
    "    plt.gca().add_patch(t1)\n",
    "    \n",
    "def draw_circle():\n",
    "    r = np.random.uniform(0.1, 0.25)\n",
    "    x = np.random.uniform(0+r, 1-r)\n",
    "    y = np.random.uniform(0+r, 1-r)\n",
    "\n",
    "    circle1 = plt.Circle((x, y), r, color='black')\n",
    "    plt.gcf().gca().add_artist(circle1)\n",
    "    \n",
    "def create_image(form, path):\n",
    "    plt.figure(figsize=(1, 1))\n",
    "    if form == 'circle':\n",
    "        draw_circle()\n",
    "    elif form == 'triangle':\n",
    "        draw_triangle()\n",
    "    plt.axis('off')\n",
    "    plt.savefig(path, dpi=80, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    \n",
    "def create_images(path):\n",
    "    nb_circles = 100\n",
    "    nb_triangles = 100\n",
    "    \n",
    "    for i in range(nb_circles):\n",
    "        c_path = os.path.join(path, 'circles', f'circle_{i}.png')\n",
    "        create_image('circle', c_path)\n",
    "        \n",
    "    for i in range(nb_triangles):\n",
    "        t_path = os.path.join(path, 'triangles', f'triangle_{i}.png')\n",
    "        create_image('triangle', t_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
