{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 - Written Digits Classification (MNIST)\n",
    "\n",
    "Now that you know how to manipulate images, we will start with another classic dataset: MNIST. This is a dataset with black and white images of written digits between 0 and 9. So there are 9 categories and the goal will be to create a model that can categorize these images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Data Visualization and Preparation\n",
    "\n",
    "As usual, the first thing to do is to look at the training data. You can do the following steps:\n",
    "\n",
    "- Check the number of classes\n",
    "- Check how many samples are in each class\n",
    "- Take some time to visualize few images in different categories and ask yourself some questions: what is the task we want the algorithm to do? Would you be able to do it as a human? Would it be easy? Would it be as easy for every samples you looked at?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now reshape the training and test data into (samples by pixels). This is needed to use them as input of machine learning algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should end up with `X_train` with shape `(60000, 784)` and `X_test` with shape `(10000, 784)`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Modeling\n",
    "\n",
    "Now, you will built a classifier that takes hand-written digits as input and estimate the corresponding digit (class between 0 and 9). The goal of this challenge is to reach more than 90% accuracy. Train the three following algorithms:\n",
    "\n",
    "- 1- Logistic regression (use `solver='lbfgs'` to speed-up the training)\n",
    "- 2- Random forest\n",
    "- 3- Optional: kNN. This one is optional because the prediction phase take a long time: around 10 minutes on my computer. You can try it if you need a coffee break.\n",
    "\n",
    "Then evaluate their performance (do the predictions and compare `y_pred` with `y_test` rather than using the `model.score()` function to keep the predictions and investigate the model errors) and the training and testing time of each algorithm.\n",
    "\n",
    "In addition, find a way to visualize what the model did by plotting the weights as it was an image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1- Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2- Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 - kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Errors\n",
    "\n",
    "Now, you will look at the model errors. This is a very important step in machine learning and deep learning. It will for instance allow you to:\n",
    "\n",
    "- check that there is no bug in your code\n",
    "- spot the labeling errors\n",
    "- understand the characteristics that make your model fail\n",
    "\n",
    "To do this error investigation, plot random misclassified images with their true labels for each classifier you built."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, try to compare the misclassification images for the random forest and logistic regression. We want to see if the same data samples are misclassified by the two models. One way to evaluate that is to calculate the number of samples misclassified by both models and compare this number to the number of misclassification for each model separately.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These number shows that only a small part of the misclassifications are identical for the two models (around 60% of the misclassifications of the best model)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Confusion Matrix\n",
    "\n",
    "To look at the errors in more concise way, you can use a confusion matrix. The following image is taken from Aurélien Géron's book: Hands-on Machine Learning and illustrate how to read the confusion matrix:\n",
    "\n",
    "<img src=\"geron_confusion_matrix.png\" width=600>\n",
    "\n",
    "In our case, there are multiple classes, not only true but it works the same.\n",
    "\n",
    "Try to display the confusion matrices of both classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From these confusion matrices, what is the digit that is better categorized with random forest (explaining the difference in performance)?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 New Data\n",
    "\n",
    "It seems quite impressive to have an accuracy of more than 90%. Do you think that it would work as well on custom data? To check that, I drew few numbers. Try to make predictions from these images to see if your classifier is robust to new data (and to my writing).\n",
    "\n",
    "First, plot the images from the files `test_1.png` to `test_12.png` to look at the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, use your two or three algorithms to see how it performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performances don't look as good as when we tested it on the test set. What could explain this? Even by splitting the dataset into training set and test set, data look quite homogeneous: all digits have a black background for instance. It seems also that each data sample is not unique but duplicated. If there are only few different data sample and that they are the same in the training set and the test set, it is normal that the algorithm has trouble with new data.\n",
    "\n",
    "Feel free to try to write some digits and try them. It just need to be black and white images of size 28 x 28."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
